{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "===\n",
    "This notebook filters and sets up the input traces for the\n",
    "Matlab model building script.\n",
    "\n",
    "Setup\n",
    "---\n",
    "Set the working directory below. The working directory should \n",
    "include the signal (power values) traces and trigger traces. \n",
    "This is generated by running the output of `genasm.py <state>` \n",
    "on a device. These files should be in their respective directories\n",
    "according to what state changes applied to generate them (i.e.\n",
    "files that are related to `ldr` is in `ldr-state` in the working\n",
    "directory). If these files need to be averaged for noise reduction\n",
    "please put them in `<working-dir>/<xxx-state>/run_N`, where `N` is\n",
    "an starts with `0`. Use `BinTraces.merge` to load the them, otherwise\n",
    "concatenate all the runs to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'BinTraces' from '/home/samiko/Desktop/rosita/analyze_traces/BinTraces.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mmap\n",
    "import struct\n",
    "import os\n",
    "import numpy\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# include analyze_traces repo as we \n",
    "# depend on some modules from it\n",
    "sys.path.append('/home/samiko/Desktop/rosita/analyze_traces')\n",
    "import BinTraces\n",
    "import Pool\n",
    "\n",
    "# current working directory, the traces are loaded from here\n",
    "os.chdir(\"/home/samiko/Desktop/rosita/cwmodel/\") \n",
    "importlib.reload(BinTraces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Notes:\n",
    "# A array contains the signal data\n",
    "# B array contains the trigger data where the signals start\n",
    "# state_dir is the current state used on genasm.py (i.e. genasm.py ldr-state)\n",
    "#A = BinTraces.BinTraces(\"capture_A.xrc\")\n",
    "#B = BinTraces.BinTraces(\"capture_B.xrc\")\n",
    "\n",
    "# Trace sources for the state under test\n",
    "# pick one at a time\n",
    "state_dir = \"ldr-state\"\n",
    "#state_dir = \"eors-state\"\n",
    "#state_dir = \"str-state\"\n",
    "#state_dir = \"movs-state\"\n",
    "#state_dir = \"no-state\"\n",
    "\n",
    "#A = BinTraces.merge(state_dir, \"capture_A.xrc\")\n",
    "#B = BinTraces.merge(state_dir, \"capture_B.xrc\")\n",
    "\n",
    "SAMPLES_PER_CYCLE = 9.76\n",
    "# number of instruction state classes (i.e. ldr,str,eors,movs,none)\n",
    "nI = 5\n",
    "nIC = 5*5*5\n",
    "# number of samples in Point of Interest: default is 200 sample from the start\n",
    "# of an trigger\n",
    "nPOISamples = 200 \n",
    "# number of traces to process \n",
    "N = 1000\n",
    "\n",
    "# following is hardcoded values for the begining of \n",
    "# each instruction triplet, according to the output\n",
    "# of `genasm.py`\n",
    "if state_dir.startswith('ldr-state'):\n",
    "    # (11+5)(trigger and pop) +(1+1+2+1)(ldr values)+(5)(movs r7,r7 x5)\n",
    "    CYCLES_FROM_TRIGGER=11+5+(1+1+1+2+1+1+1+2+1)+(5) \n",
    "elif state_dir.startswith('str-state'):\n",
    "    CYCLES_FROM_TRIGGER=11+5+(1+2+1+2+1+1+1+2+1)+(5) \n",
    "elif state_dir.startswith('eors-state'):\n",
    "    CYCLES_FROM_TRIGGER=11+5+(1+2+1+2+2+1+1+1+1)+(5)\n",
    "elif state_dir.startswith('movs-state'):\n",
    "    CYCLES_FROM_TRIGGER=11+5+(1+2+1+2+2+1+1+1+1)+(5)\n",
    "elif state_dir.startswith('no-state'):\n",
    "    CYCLES_FROM_TRIGGER=11+5+(1+2+1+2+2+1+1+1+1)+(5)\n",
    "else:\n",
    "    raise BaseException(\"invalid state\")\n",
    "    \n",
    "print(CYCLES_FROM_TRIGGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise\n",
    "\n",
    "def trace_thres(work):\n",
    "    ctx, start, end = work\n",
    "    POI_S = []\n",
    "    for idx in range(start, end):\n",
    "        xb=B.read_trace(idx)\n",
    "        t=1500\n",
    "        #V1 = (xb[:-1] < t) & (xb[1:] > t)\n",
    "        V2 = (xb[:-1] > t) & (xb[1:] < t)\n",
    "\n",
    "        #C = np.flatnonzero(V1 | V2) +1\n",
    "        C = np.flatnonzero(V2) + 2 # falling edge\n",
    "\n",
    "        assert np.shape(C)[0] == 125, np.shape(C)[0]\n",
    "\n",
    "        # after trigger + pop instrs\n",
    "        # offset to first instruction after falling edge\n",
    "        POI_S.append( C + int(round(CYCLES_FROM_TRIGGER*SAMPLES_PER_CYCLE)) ) \n",
    "    return POI_S\n",
    "\n",
    "p = Pool.Mapper(8, 1000, trace_thres)\n",
    "S = p.merge([], lambda acc,x: acc.extend(x))\n",
    "np.save(\"%s/POI_S.npy\" % (state_dir), np.asarray(S), allow_pickle=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from disk ldr-state (1000, 125)\n"
     ]
    }
   ],
   "source": [
    "POI_S = np.load(\"%s/POI_S.npy\"% (state_dir))\n",
    "print(\"loaded from disk\", state_dir, POI_S.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# Debug only:\n",
    "# Check if set of traces align \n",
    "def pick(work):\n",
    "    ctx, start, end = work\n",
    "    cut_samples = []\n",
    "    for idx in range(start, end):\n",
    "        range_samples = []\n",
    "        for at in range(0, np.shape(POI_S)[1]):\n",
    "            cut_sample = A.read(idx, POI_S[idx][at]-10, nPOISamples)\n",
    "            range_samples.append(cut_sample)\n",
    "        cut_samples.append(range_samples)\n",
    "    \n",
    "    return cut_samples \n",
    "samples=np.asarray(pick((None, 0, 1000)))\n",
    "\n",
    "print(samples.shape)\n",
    "print(POI_S[[0,5,10,20],0])\n",
    "g=20\n",
    "h=1\n",
    "plt.plot(samples[g+0,h,:50])\n",
    "plt.plot(samples[g+5,h,:50])\n",
    "plt.plot(samples[g+10,h,:50])\n",
    "plt.plot(samples[g+20,h,:50])\n",
    "plt.plot(samples[g+30,h,:50])\n",
    "plt.plot(samples[g+50,h,:50])\n",
    "S= samples[:,85,:]\n",
    "#print(S)\n",
    "np.save('DD.npy',S,allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging 1 times\n",
      "0 / 1000\n",
      "128 / 1000\n",
      "256 / 1000\n",
      "384 / 1000\n",
      "512 / 1000\n",
      "640 / 1000\n",
      "768 / 1000\n",
      "896 / 1000\n"
     ]
    }
   ],
   "source": [
    "# Since there can be discrepancies in averaging\n",
    "# the whole signal traces without aligning and splitting\n",
    "# by the triggers, we instead average on the split \n",
    "# signals\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "AVG = np.zeros((N, nIC, nPOISamples), dtype=np.float)\n",
    "xN = np.shape(POI_S)[0] // N\n",
    "print(\"averaging %d times\" % (xN))\n",
    "vv =[]\n",
    "divk = 1.0/xN\n",
    "for k in range(0, N): # avg trace\n",
    "    POI_wind_total = np.zeros((nIC, nPOISamples), dtype=np.float)\n",
    "    temp = np.zeros((nPOISamples), dtype=np.float)\n",
    "    for j in range(k, np.shape(POI_S)[0], N): # trace\n",
    "        for i in range(0, nIC):\n",
    "            #sliding_wind(temp, A.read(j, POI_S[j][i], nPOISamples), 8)\n",
    "            POI_wind = A.read(j, POI_S[j][i], nPOISamples)\n",
    "            POI_wind_total[i,:] += POI_wind\n",
    "        AVG[k,:] = POI_wind_total * divk\n",
    "    if k % 128 == 0:\n",
    "        print(k,\"/\",N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving intermediates to ldr-state\n"
     ]
    }
   ],
   "source": [
    "print(\"saving intermediates to %s\"%state_dir)\n",
    "np.save(\"%s/AVG.npy\"% (state_dir), AVG)\n",
    "#np.save(\"%s/POI_S.npy\"% (state_dir), POI_S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the start and end of intructions\n",
    "# in samples and then compress the sample ranges\n",
    "# in to single values (COMP will hold the \n",
    "# compressed values)\n",
    "K=SAMPLES_PER_CYCLE\n",
    "COMP = np.zeros((N, nIC, 3), dtype=np.float)\n",
    "#STATE = np.zeros((N,4), dtype=np.float)\n",
    "#GGG = np.zeros((N,200), dtype=np.float)\n",
    "Nx = np.shape(POI_S)[0] / N\n",
    "\n",
    "\n",
    "for i in range(0, N):\n",
    "    COMPx = np.zeros((nIC, 3), dtype=np.float)\n",
    "    # 125 permutations + 4 state transisions\n",
    "    # tr = A.read_trace(i)\n",
    "    for j in range(0, nIC): \n",
    "        insts = INSTS[j]\n",
    "        avg = AVG[i, j]\n",
    "        cycles_s = [0, insts[0]*K, (insts[0]+insts[1])*K]\n",
    "        cycles_e = [insts[0]*K, (insts[0]+insts[1])*K, (insts[0]+insts[1]+insts[2])*K]\n",
    "        \n",
    "        comp = []\n",
    "        for rr in range(0, 3):\n",
    "            tr = avg[int(round(cycles_s[rr])):int(round(cycles_e[rr]))]\n",
    "            comp.append(np.max(tr))\n",
    "            \n",
    "        COMPx[j] = np.asarray(comp)\n",
    "    COMP[i] = COMPx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 10, 2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "trace_array = np.load(\"/home/samiko/Desktop/rosita/cwmodel/ldr-state/ldr_state.npy\")\n",
    "trace_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert np.shape(COMP)[0] == N \n",
    "for i in range(0, N):\n",
    "    assert np.shape(COMP[i])[0] == nIC\n",
    "inputs = [x.rstrip('\\n') for x in open(\"%s/run_0/prf_input.txt\"%(state_dir)).readlines()]\n",
    "inputs = inputs[:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[195   5 113 ...  22 125  78]\n",
      " [165 155 169 ...  46  23 128]\n",
      " [200 239 139 ...  84 247 240]\n",
      " ...\n",
      " [222 105 190 ... 162  71 173]\n",
      " [159 202  82 ... 248 189 212]\n",
      " [246 230 128 ...  36  77 192]]\n"
     ]
    }
   ],
   "source": [
    "v = lambda x: ((int(x[0:8],16),int(x[8:16],16)),\n",
    "               (int(x[16:24],16),int(x[24:32],16)),\n",
    "               (int(x[32:40],16),int(x[40:48],16)),\n",
    "               (int(x[48:56],16),int(x[56:64],16)))\n",
    "npV = lambda x: [int(x[0:8],16),int(x[8:16],16),int(x[16:24],16),int(x[24:32],16),int(x[32:40],16),int(x[40:48],16),int(x[48:56],16),int(x[56:64],16)]\n",
    "INPUTS = list(map(v, inputs))\n",
    "npINPUTS = np.asarray(list(map(npV, inputs)))\n",
    "\n",
    "inputbytes = list(map(bytes.fromhex, inputs))\n",
    "splitbytes = lambda x: struct.unpack('B'*32, x)\n",
    "\n",
    "inputints = np.asarray(list(map(splitbytes, inputbytes)),dtype=np.uint32)\n",
    "print(inputints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36705/4003365633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb8_0\u001b[0m\u001b[0;34m<<\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb8_1\u001b[0m\u001b[0;34m<<\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb8_2\u001b[0m\u001b[0;34m<<\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb8_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>>\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inputints' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def _m(k):\n",
    "    return k & 0xff\n",
    "def _hw(k):\n",
    "    k = k & 0xffffffff\n",
    "    return bin(k).count('1')\n",
    "def _hd(k,l):\n",
    "    return _hw(k ^ l)\n",
    "def prng(x):\n",
    "    x = (1103515245*x + 12345) & 0xffffffff;\n",
    "    return x\n",
    "    #return (241*x + 17) & 0xff\n",
    "def incr(seeds):\n",
    "    seeds = seeds & 0xffffffff\n",
    "    #return (_m(_m(cc >> 24) +1)<<24) | (_m(_m(cc >> 16) +1)<<16) | (_m(_m(cc >> 8) +1)<<8)  | (_m(_m(cc) +1)) \n",
    "    seeds[0], b8_0 = func256(seeds[0])\n",
    "    seeds[1], b8_1 = func256(seeds[1])\n",
    "    seeds[2], b8_2 = func256(seeds[2])\n",
    "    seeds[3], b8_3 = func256(seeds[3])\n",
    "    return (b8_0<<24) | (b8_1<<16) | (b8_2<<8) | (b8_3) \n",
    "\n",
    "print(prng(inputints)>>24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('%s-comp.npy'%(state_dir),COMP,allow_pickle=False)\n",
    "np.save('%s-input.npy'%(state_dir),INPUTS,allow_pickle=False)\n",
    "np.save('%s-opcodes.npy'%(state_dir),OPCODES,allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(INSTS) == nIC, len(INSTS)\n",
    "assert len(OPCODES) == nIC, len(OPCODES)\n",
    "assert len(COMP) == N, len(COMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7732f96b91be448a9651a02f4e925368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging traces:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 10, 2000)\n",
      "(125, 10, 2000)\n",
      "(125, 10, 2000)\n",
      "(125, 10, 2000)\n",
      "(125, 10, 2000)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tnrange\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import glob\n",
    "\n",
    "states = ['ldr-state', 'str-state', 'eors-state', 'movs-state', 'no-state']\n",
    "\n",
    "N = 5\n",
    "for i in tnrange(N, desc='Merging traces'):\n",
    "    basepath = \"/home/samiko/Desktop/rosita/cwmodel/{}/\".format(states[i])\n",
    "    npypath = \"/home/samiko/Desktop/rosita/cwmodel/{}/traces\".format(states[i])\n",
    "\n",
    "    os.chdir(npypath)\n",
    "    npfiles = glob.glob(\"*.npy\")\n",
    "    npfiles.sort()\n",
    "\n",
    "    trace_array = []\n",
    "    for npfile in npfiles:\n",
    "        trace_array.append(np.load(os.path.join(npypath, npfile)))\n",
    "\n",
    "    trace_array = np.array(trace_array)  \n",
    "    print(trace_array.shape)\n",
    "\n",
    "    os.chdir(basepath)\n",
    "    with open(\"{}.npy\".format(states[i].replace('-','_')), 'wb') as f:\n",
    "        np.save(f, trace_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " ...\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]]\n",
      "(1250, 3)\n"
     ]
    }
   ],
   "source": [
    "# from ELMO model\n",
    "OPCODES_S = ['eors','lsls','str','ldr','movs'] \n",
    "# from state leakage matrix \n",
    "STATE_S = ['eors','str','ldr','movs'] \n",
    "insts_len = [1,1,2,2,1]\n",
    "INSTS = []\n",
    "\n",
    "OPCODES = []\n",
    "idx = 0\n",
    "eors_idxes = []\n",
    "N_TEST = 10\n",
    "N_INST = 5*5*5\n",
    "\n",
    "def insts_part():\n",
    "    return  range(0, len(insts_len))\n",
    "for idx1 in insts_part():\n",
    "    for idx2 in insts_part():\n",
    "        for idx3 in insts_part():\n",
    "            OPCODES += [(idx1+1,idx2+1,idx3+1)]\n",
    "            #if (OPCODES_S[idx1] == \"ldr\"):\n",
    "            #    print(idx, OPCODES_S[idx1], OPCODES_S[idx2], OPCODES_S[idx3])\n",
    "            INSTS += [(insts_len[idx1],insts_len[idx2],insts_len[idx3])]\n",
    "            idx +=1\n",
    "\n",
    "nOPCODES = np.zeros((N_R,3))\n",
    "for i in range(0, N_INST):\n",
    "    for j in range(0, N_TEST):\n",
    "        nOPCODES[i*N_TEST + j][0] = OPCODES[i][0]\n",
    "        nOPCODES[i*N_TEST + j][1] = OPCODES[i][1]\n",
    "        nOPCODES[i*N_TEST + j][2] = OPCODES[i][2]\n",
    "\n",
    "print(nOPCODES)\n",
    "print(nOPCODES.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04453125]\n",
      " [0.04277344]\n",
      " [0.0421875 ]\n",
      " ...\n",
      " [0.04453125]\n",
      " [0.04179687]\n",
      " [0.04140625]]\n",
      "(1250, 1)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tnrange\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "N_TEST= 10\n",
    "N_INST= 5*5*5\n",
    "\n",
    "N_R = N_INST*N_TEST\n",
    "\n",
    "trace_array = np.load(\"/home/samiko/Desktop/rosita/cwmodel/no-state/no_state.npy\")\n",
    "\n",
    "nTRACES = np.zeros((N_R,1), dtype=np.double)\n",
    "w = 0\n",
    "for i in range(0, N_INST):\n",
    "    for j in range(0, N_TEST):\n",
    "        nTRACES[w] = -np.mean(trace_array[i][j][150:170])\n",
    "        w += 1\n",
    "\n",
    "print(nTRACES)\n",
    "print(nTRACES.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "N_TEST= 10\n",
    "N_INST= 5*5*5\n",
    "\n",
    "N_R = N_INST*N_TEST\n",
    "\n",
    "nINPUT1 = np.zeros((N_R,2), dtype=np.double)\n",
    "nINPUT2 = np.zeros((N_R,2), dtype=np.double)\n",
    "nINPUT3 = np.zeros((N_R,2), dtype=np.double)\n",
    "nSTATEINP = np.zeros((N_R,2), dtype=np.double)\n",
    "\n",
    "for i in range(0,N_R):\n",
    "    nINPUT1[i][0] = randint(10000000, 999999999)\n",
    "    nINPUT1[i][1] = randint(10000000, 999999999)\n",
    "    nINPUT2[i][0] = randint(10000000, 999999999)\n",
    "    nINPUT2[i][1] = randint(10000000, 999999999)\n",
    "    nINPUT3[i][0] = randint(10000000, 999999999)\n",
    "    nINPUT3[i][1] = randint(10000000, 999999999)\n",
    "    nSTATEINP[i][0] = randint(10000000, 999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36705/1195855378.py:5: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  _c = np.zeros((1,3), dtype=np.object)\n",
      "/tmp/ipykernel_36705/1195855378.py:10: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  _s = np.zeros((1,5), dtype=np.object)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "OPCODES_S = ['eors','lsls','str','ldr','movs'] \n",
    "\n",
    "_c = np.zeros((1,3), dtype=np.object)\n",
    "_c[0][0] = nINPUT1\n",
    "_c[0][1] = nINPUT2\n",
    "_c[0][2] = nINPUT3\n",
    "\n",
    "_s = np.zeros((1,5), dtype=np.object)\n",
    "_s[0][0] = OPCODES_S[0]\n",
    "_s[0][1] = OPCODES_S[1]\n",
    "_s[0][2] = OPCODES_S[2]\n",
    "_s[0][3] = OPCODES_S[3]\n",
    "_s[0][4] = OPCODES_S[4]\n",
    "dictx = {\n",
    "    'opcodes': nOPCODES,\n",
    "    'input': _c,\n",
    "    'trace': nTRACES,\n",
    "    'oplist': _s\n",
    "}\n",
    "scipy.io.savemat('m-no.mat',mdict=dictx)\n",
    "scipy.io.savemat('state-no.mat',mdict={'state_input': nSTATEINP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INPUTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36705/1236892877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0minp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'INPUTS' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "nIC = 5*5*5\n",
    "\n",
    "N_TEST= N\n",
    "N_INST= nIC\n",
    "\n",
    "OPCODES_S = ['eors','lsls','str','ldr','movs'] \n",
    "\n",
    "N_R = N_INST*N_TEST#(N_INST+4)*N_TEST\n",
    "\n",
    "def make_seeds(inp, seeds):\n",
    "    seeds[0] = (inp & 0xff000000) >> 24\n",
    "    seeds[1] = (inp & 0xff0000) >> 16\n",
    "    seeds[2] = (inp & 0xff00) >> 8\n",
    "    seeds[3] = (inp & 0xff)\n",
    "def getmsbyte(i32):\n",
    "    return (i32 >> 24) & 0xff\n",
    "def movetomsbyte(i32):\n",
    "    return i32 << 24\n",
    "def make_int(inpbytes, indx):\n",
    "    return (getmsbyte(inpbytes[indx]) << 24) | (getmsbyte(inpbytes[indx+1]) << 16) | (getmsbyte(inpbytes[indx+2]) << 8) | getmsbyte(inpbytes[indx+3])\n",
    "\n",
    "nOPCODES = np.zeros((N_R,3))\n",
    "nINPUT1 = np.zeros((N_R,2), dtype=np.double)\n",
    "nINPUT2 = np.zeros((N_R,2), dtype=np.double)\n",
    "nINPUT3 = np.zeros((N_R,2), dtype=np.double)\n",
    "nTRACES = np.zeros((N_R,1), dtype=np.double)\n",
    "nSTATEINP = np.zeros((N_R,2), dtype=np.double)\n",
    "\n",
    "seeds = np.zeros((8,4), dtype=np.uint32)\n",
    "\n",
    "g=[]\n",
    "#print(np.shape(INPUTS))\n",
    "for i in range(0, N_TEST):\n",
    "    inp1 = INPUTS[i][0]\n",
    "    inp2 = INPUTS[i][1]\n",
    "    inp3 = INPUTS[i][2]\n",
    "    inp4 = INPUTS[i][3]\n",
    "    \n",
    "    testinpints = inputints[i]\n",
    "    prngout = movetomsbyte(testinpints)\n",
    "    #print(len(testinpints))\n",
    "    POI_IDX = 1\n",
    "    for j in range(0, N_INST):\n",
    "        \n",
    "        # in ldr and str leakage happens in the later cycle rather\n",
    "        # than in the current cycle. Therefore, below code overrides \n",
    "        # the power value from the subsequent instruction\n",
    "        if OPCODES_S[OPCODES[j][1]-1]== \"str\" or  OPCODES_S[OPCODES[j][1]-1]== \"ldr\":\n",
    "            POI_IDX=2\n",
    "            \n",
    "        nOPCODES[i*N_INST + j,0] = OPCODES[j][0] \n",
    "        nOPCODES[i*N_INST + j,1] = OPCODES[j][1]\n",
    "        nOPCODES[i*N_INST + j,2] = OPCODES[j][2]\n",
    "        \n",
    "        nINPUT1[i*N_INST + j] = (make_int(prngout, 0), make_int(prngout, 4))#inp1\n",
    "        nINPUT2[i*N_INST + j] = (make_int(prngout, 8), make_int(prngout, 12))#inp2\n",
    "        nINPUT3[i*N_INST + j] = (make_int(prngout, 16), make_int(prngout, 20))#inp3\n",
    "        \n",
    "        nSTATEINP[i*N_INST + j] = (make_int(prngout, 24), make_int(prngout, 28))#inp4\n",
    "\n",
    "        nTRACES[i*N_INST + j] = COMP[i][j][POI_IDX] / 100000.0\n",
    "        #inp1 = tuple(map(incr,inp1))\n",
    "        #inp2 = tuple(map(incr,inp2))\n",
    "        #inp3 = tuple(map(incr,inp3))\n",
    "        #inp4 = tuple(map(incr,inp4))\n",
    "        #print(testinpints)\n",
    "        \n",
    "        testinpints = prng(testinpints)\n",
    "        prngout = testinpints\n",
    "    \n",
    "    #for j in range(N_INST, N_INST+4):\n",
    "        \n",
    "    #    nTRACES[i*N_INST + j] = COMP[i][j][1] / 100000.0\n",
    "        \n",
    "    #    if _hd(inp1[0],inp2[1]) == 11:\n",
    "    #        #print(_hd(inp1[0],inp2[1]))\n",
    "    #        g.append(nTRACES[i*N_INST + j][0])\n",
    "    #    #print(_hd(inp1[0],inp2[1]))\n",
    "    #    inp1 = tuple(map(incr,inp1))\n",
    "    #    inp2 = tuple(map(incr,inp2))\n",
    "    #    inp3 = tuple(map(incr,inp3))\n",
    "import scipy.io\n",
    "\n",
    "_c = np.zeros((1,3), dtype=np.object)\n",
    "_c[0][0] = nINPUT1\n",
    "_c[0][1] = nINPUT2\n",
    "_c[0][2] = nINPUT3\n",
    "_s = np.zeros((1,5), dtype=np.object)\n",
    "_s[0][0] = OPCODES_S[0]\n",
    "_s[0][1] = OPCODES_S[1]\n",
    "_s[0][2] = OPCODES_S[2]\n",
    "_s[0][3] = OPCODES_S[3]\n",
    "_s[0][4] = OPCODES_S[4]\n",
    "dictx = {\n",
    "    'opcodes': nOPCODES,\n",
    "    'input': _c,\n",
    "    'trace': nTRACES,\n",
    "    'oplist': _s\n",
    "}\n",
    "scipy.io.savemat('m-%s.mat'%(state_dir.replace('-state','')),mdict=dictx)\n",
    "scipy.io.savemat('state-%s.mat'%(state_dir.replace('-state','')),mdict={'state_input': nSTATEINP})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
